name: Nightly Benchmark Suite

on:
  schedule:
    # Run at 2 AM UTC every day
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      runs:
        description: 'Number of benchmark runs'
        required: false
        default: '20'
      include_memory:
        description: 'Include memory profiling'
        required: false
        default: 'true'

env:
  CARGO_TERM_COLOR: always

jobs:
  # ==========================================================================
  # Full Benchmark Suite
  # ==========================================================================
  full-benchmark:
    name: Full Benchmark Suite
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0

      - name: Setup Rust
        uses: dtolnay/rust-action@stable

      - name: Install LLVM 21
        run: |
          wget https://apt.llvm.org/llvm.sh
          chmod +x llvm.sh
          sudo ./llvm.sh 21
          echo "LLVM_SYS_210_PREFIX=/usr/lib/llvm-21" >> $GITHUB_ENV
          echo "/usr/lib/llvm-21/bin" >> $GITHUB_PATH

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y bc valgrind linux-tools-common linux-tools-generic

      - name: Cache cargo
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
            target/
          key: ubuntu-cargo-llvm-${{ hashFiles('**/Cargo.lock') }}

      - name: Build BMB with LLVM
        run: cargo build --release --features llvm

      - name: Build BMB Runtime
        run: |
          cd bmb/runtime
          clang -c bmb_runtime.c -o bmb_runtime.o -O3
          ar rcs libbmb_runtime.a bmb_runtime.o
          echo "BMB_RUNTIME_PATH=$(pwd)/libbmb_runtime.a" >> $GITHUB_ENV

      - name: Get previous baseline
        id: baseline
        run: |
          git fetch origin main
          if git show origin/main:.baseline.json > baseline.json 2>/dev/null; then
            echo "found=true" >> $GITHUB_OUTPUT
          else
            echo "found=false" >> $GITHUB_OUTPUT
          fi

      - name: Run Full Benchmark Suite
        run: |
          chmod +x scripts/benchmark.sh
          RUNS=${{ github.event.inputs.runs || '20' }}
          ./scripts/benchmark.sh --tier all --runs $RUNS --output nightly_benchmarks.json

      - name: Compare with Baseline
        if: steps.baseline.outputs.found == 'true'
        run: |
          python3 scripts/compare.py \
            baseline.json \
            nightly_benchmarks.json \
            --tier1-threshold 2 \
            --threshold 5 \
            --output nightly_comparison.txt \
            --json > nightly_comparison.json

      - name: Memory Profiling
        if: ${{ github.event.inputs.include_memory != 'false' }}
        run: |
          mkdir -p memory_results

          # Profile key benchmarks
          for bench in fibonacci mandelbrot sieve; do
            if [ -f "ecosystem/benchmark-bmb/benches/compute/$bench/bmb/main.bmb" ]; then
              echo "Memory profiling: $bench"
              ./scripts/perf-analyze.sh "$bench" --memory --output memory_results/ || true
            fi
          done

      - name: Generate Report
        run: |
          DATE=$(date -u +"%Y-%m-%d")

          echo "# Nightly Benchmark Report - $DATE" > nightly_report.md
          echo "" >> nightly_report.md

          echo "## Summary" >> nightly_report.md
          echo "" >> nightly_report.md

          if [ -f nightly_comparison.txt ]; then
            echo "\`\`\`" >> nightly_report.md
            cat nightly_comparison.txt >> nightly_report.md
            echo "\`\`\`" >> nightly_report.md
          fi

          echo "" >> nightly_report.md
          echo "## Raw Results" >> nightly_report.md
          echo "" >> nightly_report.md
          echo "\`\`\`json" >> nightly_report.md
          cat nightly_benchmarks.json >> nightly_report.md
          echo "\`\`\`" >> nightly_report.md

      - name: Upload Results
        uses: actions/upload-artifact@v4
        with:
          name: nightly-benchmark-${{ github.run_number }}
          path: |
            nightly_benchmarks.json
            nightly_comparison.txt
            nightly_comparison.json
            nightly_report.md
            memory_results/

      - name: Post Summary
        run: |
          cat nightly_report.md >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # Historical Trend Analysis
  # ==========================================================================
  trend-analysis:
    name: Trend Analysis
    runs-on: ubuntu-latest
    needs: full-benchmark
    steps:
      - uses: actions/checkout@v4

      - name: Download current results
        uses: actions/download-artifact@v4
        with:
          name: nightly-benchmark-${{ github.run_number }}
          path: current/

      - name: Analyze Trends
        run: |
          echo "# Performance Trends" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "To view historical trends, check the benchmark artifacts in GitHub Actions." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Recent runs can be compared using:" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          echo "python3 scripts/compare.py <older>.json <newer>.json" >> $GITHUB_STEP_SUMMARY
          echo "\`\`\`" >> $GITHUB_STEP_SUMMARY

  # ==========================================================================
  # Notify on Regression
  # ==========================================================================
  notify:
    name: Notify on Regression
    runs-on: ubuntu-latest
    needs: full-benchmark
    if: failure()
    steps:
      - name: Create Issue on Regression
        uses: actions/github-script@v7
        with:
          script: |
            const date = new Date().toISOString().split('T')[0];
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `[Nightly] Performance regression detected - ${date}`,
              body: `The nightly benchmark run detected a performance regression.

              **Run:** https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}

              Please investigate and fix the regression before merging new changes.`,
              labels: ['performance', 'regression', 'automated']
            });
